{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template Notebook for DS Project\n",
    "Short description of the project\n",
    "\n",
    "**Contents:**\n",
    "\n",
    "* [Step 0: Notes regarding this notebook](#step0)\n",
    "* [Step 1: Understand the problem and define the project](#step1)\n",
    "* [Step 2: Data acquisition](#step2)\n",
    "* [Step 3: Exploratory data analysis - clean and understand data](#step3)\n",
    "* [Step 4: Enrich data set with additional data ](#step4)\n",
    "* [Step 5: Build helpful visualizations for communication](#step5)\n",
    "* [Step 6: Get predictive - machine learning](#step6)\n",
    "* [Step 7: Iterate and maintain](#step7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Notes regarding this notebook <a id='step0'></a>\n",
    "This notebook serves as a guideline for a standard data science workflow and contains tips and code snippets to increase efficiency when working on data science projects in Python/jupyter notebooks.\n",
    "\n",
    "Obviously every project is different and this notebook just serves as a general help and guideline. It is work in [progress](https://github.com/jstehr91/ds-template-notebook). \n",
    "\n",
    "### Jupyter Notebook [tips and tricks](https://www.dataquest.io/blog/jupyter-notebook-tips-tricks-shortcuts/)\n",
    "**Command mode:** Navigate around notebook\n",
    "* `A`: insert a new cell above the current cell\n",
    "* `B`: insert a new cell below the current cell\n",
    "* `M`: change the current cell to Markdown\n",
    "* `Y`: change the current cell to code\n",
    "* `D (2X)`: delete cell\n",
    "* `Shift + M`: merge multiple selected cells\n",
    "\n",
    "**Edit mode:** Edit individual cells\n",
    "* `Ctrl + Shift + -`: split the current cell where cursor is\n",
    "* `Shift + Tab`: shows docstring documentation of current object\n",
    "* `Ctrl + Shift + -`: split the current cell where cursor is\n",
    "\n",
    "**See all shortcuts:** `H` in command mode "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions - best practices\n",
    "What we should keep in mind when defining functions:\n",
    "\n",
    "* **Don't repeat yourself** (DRY): whenever we reuse code snippets multiple times, think about creating a function for them\n",
    "* **Do one thing** (DOT): if possible split your functions so that they do only one thing and can be reused in many cases (`load_and_plot()` is not as variable as `load_data()` and a separate `plot_graph()` function)\n",
    "* **Document**: write a docstring to describe the function\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(arg_1, arg_2=42):\n",
    "    \"\"\"Description of what the function does.\n",
    "\n",
    "    Args:\n",
    "      arg_1 (str): Description of arg_1 that can break onto the next line\n",
    "        if needed.\n",
    "      arg_2 (int, optional): Write optional when an argument has a default\n",
    "        value.\n",
    "\n",
    "    Returns:\n",
    "      bool: Optional description of the return value\n",
    "      Extra lines are not indented.\n",
    "\n",
    "    Raises:\n",
    "      ValueError: Include any error types that the function intentionally\n",
    "        raises.\n",
    "\n",
    "    Notes:\n",
    "      See <link> for more info.  \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Understand the problem and define the project <a id='step1'></a>\n",
    "### Understand the problem\n",
    "* Read about the field\n",
    "* Talk to experts\n",
    "* Recap problem statement\n",
    "    * What are the reasons for the request?\n",
    "    * What are the right questions to ask?\n",
    "\n",
    "### Define the project\n",
    "* Recap information from stakeholders and get confirmation\n",
    "* Have a precise question to answer\n",
    "* Set timeline\n",
    "* Define KPIs\n",
    "\n",
    "### Load necessary modules and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas_profiling'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6ac25769a054>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# profiling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas_profiling\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# dates and times and time zones and timestamps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas_profiling'"
     ]
    }
   ],
   "source": [
    "# import usual libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly\n",
    "import cufflinks as cf\n",
    "%matplotlib inline\n",
    "\n",
    "# profiling\n",
    "import pandas_profiling as pp\n",
    "\n",
    "# dates and times and time zones and timestamps\n",
    "import datetime as dt\n",
    "import time\n",
    "import pytz\n",
    "\n",
    "# create UUIDs\n",
    "import uuid\n",
    "\n",
    "# set aesthetic parameters\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show installed versions\n",
    "pd.show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpful cheat-sheets\n",
    "- Pandas: https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf\n",
    "- SQL: https://cdn.sqltutorial.org/wp-content/uploads/2016/04/SQL-cheat-sheet.pdf\n",
    "- Scikit-Learn: https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n",
    "\n",
    "Or see in GitHub repository (folder `/cheat_sheets/`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data acquisition <a id='step2'></a>\n",
    "### Datasources\n",
    "Describe the different data sources\n",
    "\n",
    "**Possible sources:**\n",
    "* Internal data bases\n",
    "* Available APIs from used services\n",
    "* Publicly available data sets\n",
    "* Requests to capture certain data\n",
    "\n",
    "**Load helpful libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REST request libraries\n",
    "import requests\n",
    "from pandas.io.json import json_normalize\n",
    "import json\n",
    "\n",
    "# SQL database packages\n",
    "import pandabase\n",
    "import psycopg2\n",
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data frames\n",
    "df = pd.DataFrame({'col one':[100, 200], 'col two':[300, 400]}) # from dict\n",
    "pd.DataFrame(np.random.rand(4, 8), columns=list('abcdefgh')) # with random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read local files\n",
    "train = pd.read_csv('train.csv') # most read_xyz methods can let you choose the separator and the header row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# API code snippets\n",
    "# define the url for the request\n",
    "url = 'www.api.com'\n",
    "# create a dictionary of headers containing our Authorization header.\n",
    "headers = {\"Authorization\": \"token 1f36137fbbe1602f779300dad26e4c1b7fbab631\"}\n",
    "# define necessary parameters\n",
    "parameters = {\"lat\": 37.78, \"lon\": -122.41}\n",
    "# Make a GET request\n",
    "response = requests.get(url, headers=headers, params=parameters)\n",
    "# get json data from response\n",
    "json_data = response.json()\n",
    "# store it in a data frame\n",
    "data_df = json.normalize(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL code snippets\n",
    "# Connect to Postgres DB\n",
    "try:\n",
    "    conn = psycopg2.connect(\"dbname='template1' user='dbuser' host='localhost' password='dbpass'\")\n",
    "except:\n",
    "    print \"I am unable to connect to the database\"\n",
    "# Define a cursor to work with\n",
    "cur = conn.cursor()\n",
    "# Run a query through the cursor\n",
    "cur.execute(\"\"\"SQL query here\"\"\")\n",
    "# Store the fetched data\n",
    "rows = cur.fetchall()\n",
    "# Close connection to DB\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excursus:** Think about context managers when connecting to databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextlib.contextmanager\n",
    "def database(url):\n",
    "    # set up database connection\n",
    "    db = postgres.connect(url)\n",
    "\n",
    "    yield db\n",
    "\n",
    "    # tear down database connection\n",
    "    db.disconnect()\n",
    "    print('goodbye')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in use:\n",
    "url = 'http://website'\n",
    "with database(url) as my_db:\n",
    "    course_list = my_db.execute(\n",
    "      'SELECT * FROM courses'\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Exploratory data analysis - clean and understand data <a id='step3'></a>\n",
    "- Inspect your data sets and figure out how you can combine them\n",
    "- Identify outliers, missing values, or human error\n",
    "- Ask questions to the specialist to understand all variables and relationships\n",
    "- Extract important variables and leave behind useless variables\n",
    "- Form first hypotheses\n",
    "- Clean your data: Make it homogenous, take care of missing data, remove duplicates in rows or columns, reclassify discrete variables if values are similar\n",
    "- Handle privacy data (tag them and make sure you're compliant)\n",
    "\n",
    "**Helpful resource:** [Data School YT Tutorials](https://www.youtube.com/playlist?list=PL5-da3qGB5ICCsgW1MxlZ0Hq8LL5U3u9y) (watch in 2x speed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpful methods for adjusting pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjusting columns\n",
    "df = df.rename({'col one':'col_one', 'col two':'col_two'}, axis='columns') # rename some specific columns\n",
    "df.columns = ['col_one', 'col_two'] # rename all columns\n",
    "df.columns = df.columns.str.replace(' ', '_') # format all columns\n",
    "df.add_prefix('X_') # add prefix to all columns (same for suffix)\n",
    "df.loc[:, ::-1] # reverse column order\n",
    "\n",
    "# adjusting rows\n",
    "df.loc[::-1] # reverse row order\n",
    "df.reset_index(drop=True) # reset index and drop old one\n",
    "\n",
    "# dropping columns and rows\n",
    "df.drop(['Names'], axis=1, inplace=True) # drops columns (axis=1) inplace\n",
    "df.isna().sum() # see number of missing values per column; .mean() gives percentage\n",
    "df.dropna(thresh=len(df)*0.9, axis='columns') # dropping columns with more than 10% missing values\n",
    "\n",
    "# sort series or data frame\n",
    "df.sort_values(['col1', 'col2'], ascending=True) # sort data frame according to multiple columns\n",
    "\n",
    "# access certain cells in a data frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpful methods for first insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape() # show no. of rows and columns\n",
    "df.info() # show columns\n",
    "df.head/sample/tail() # show sample columns\n",
    "df.columns # show columns of data set\n",
    "df.nunique(axis=0) # shows no. of unique values per column\n",
    "df.describe().apply(lambda s: s.apply(lambda x: format(x, 'f'))) # summarizes the count, mean, standard deviation, min, and max for numeric variables (following code formats data for better reading)\n",
    "\n",
    "# forming ProfileReport and save as output.html file \n",
    "profile = pp.ProfileReport(df) \n",
    "profile.to_file(\"output.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpful methods for cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reclassify: if row.column in value_list return value -> apply to column\n",
    "df.drop([columns], axis=1) # drop (duplicated) columns\n",
    "\n",
    "#Drop columns with more than x % NA values:\n",
    "NA_val = df_cleaned.isna().sum()\n",
    "def na_filter(na, threshold = .4): # only select variables that pass the threshold\n",
    "    col_pass = []\n",
    "    for i in na.keys():\n",
    "        if na[i]/df_cleaned.shape[0]<threshold:\n",
    "            col_pass.append(i)\n",
    "    return col_pass\n",
    "df_cleaned = df_cleaned[na_filter(NA_val)]\n",
    "df_cleaned.columns\n",
    "\n",
    "df[df[column] >/</==/.between(low, high)] # remove outliers: \n",
    "df.dropna(axis=0) # remove rows with Null values\n",
    "\n",
    "# convert continuous values into categorical values\n",
    "pd.cut(titanic.Age, bins=[0, 18, 25, 99], labels=['child', 'young adult', 'adult']).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpful methods on finding relationships between attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print correlation heatmap:\n",
    "corr = df.corr()\n",
    "sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, annot=True)\n",
    "\n",
    "# scatterplot to display relationship of two variables:\n",
    "df.plot(kind='scatter', x=col1, y=col2)\n",
    "\n",
    "# combine histogram per attribute and scatterplot for all relationships:\n",
    "sns.pairplot(df)\n",
    "\n",
    "# explore a single variable: \n",
    "df[col].plot(kind='hist', bins=123) #histogram\n",
    "df.boxplot(col) # boxplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpful templates for data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Enrich data set with additional data <a id='step4'></a>\n",
    "- Get most value out of the data set by combining data, clean time-based attributes\n",
    "- Analyze relationships between the variables\n",
    "- Try to not reinforce bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Build helpful visualizations for communication <a id='step5'></a>\n",
    "- Visualization is the best way to explore and communicate your findings\n",
    "- Effective way to quickly communicate a lot of information in a short period of time\n",
    "- Make the visualizations interactive and intuitive\n",
    "\n",
    "### Summary: Storytelling with Data (Cole Nussbaumer Knaflic)\n",
    "Why is it important: The amount of data and the need for data driven decisions is ever growing. When presenting data, you want to bring a point across, not the data. And even more importantly, this step is probably the only thing the audience sees of the whole data analysis/science process.\n",
    "\n",
    "#### Lessons\n",
    "1. Understand the context\n",
    "2. Choose am appropriate visual display\n",
    "3. Eliminate clutter\n",
    "4. Focus attention where you want it\n",
    "5. Think like a designer\n",
    "6. Tell a story\n",
    "\n",
    "#### Context\n",
    "- be sure to present explanatory data, not merely exploratory\n",
    "- who is the recipient? Narrow down, maybe create different communications to different groups. How do they see me?\n",
    "- what do I want them to know or do? Info only, next steps, start discussing? Slides being presented or a document being read? Which tone should you use?\n",
    "- how can I use data to make my point? \n",
    "- advice: write the 3 minute story and the big idea (one sentence)\n",
    "- advice: start with low tech - pen and paper\n",
    "\n",
    "#### Visuals\n",
    "Verbal system:\n",
    "- simple text: sometimes less is more - just give the number if there are only one or two\n",
    "- tables: great if different stakeholders need to check their respective data; use minimal borders\n",
    "- heatmap: color coding as visual aid to table\n",
    "\n",
    "Visual system:\n",
    "- scatter plot: shows relationship between things\n",
    "- line: plot continuous data\n",
    "- slope graph: comparing two states and giving visual increase or decrease\n",
    "- bar charts: good for comparing categorical data, always have 0 point in y axis\n",
    "- waterfall: good in breaking down subcategories of data or showing changes in time\n",
    "- horizontal bar chart: even easier to read!\n",
    "- area chart: good to describe order of magnitude\n",
    "\n",
    "Avoid:\n",
    "- pie and donut charts: hard to read and compare, only good to indicate share of 100%\n",
    "- 3D: skewed, full of distraction\n",
    "- secondary y axis: might be helpful, but needs time to read - alternatives are direct data labels for secondary dimension out pull apart to two graphs\n",
    "\n",
    "**Advice**: find out what's easiest to digest. Hand visuals to colleague or friend and let them describe their focus and their observations and questions\n",
    "\n",
    "#### Avoid clutter\n",
    "- keep it simple and reduce cognitive load\n",
    "- how do people perceive order in visuals? Gestalt principles of visual perception help to identify superfluous elements\n",
    "\n",
    "Gestalt principles:\n",
    "1. **Proximity**: grouping elements to clusters, rows or columns\n",
    "2. **Similarity**: through color, size, shape or orientation\n",
    "3. **Enclosure**: background shading or boxes\n",
    "4. **Closure**: if a structure is known, we don't need extra borders\n",
    "5. **Continuity**: our brain already assumes a lot, so we don't need to explicitly show everything\n",
    "6. **Connection**: lined connections are usually stronger than other similarities\n",
    "\n",
    "Formatting tips: \n",
    "\n",
    "- use left alignment to create clean lines\n",
    "- use the \"z\" shape reading pattern\n",
    "- avoid diagonal lines\n",
    "- use white space strategically\n",
    "- don't use contrast non-strategically\n",
    "\n",
    "Hint: give a summary metric if it helps (e.g. rank of own business in a comparison)\n",
    "\n",
    "#### Focus Audience Attention\n",
    "- we see with our brain (stimulus to eye to brain)\n",
    "- memory: iconic, short term, long term\n",
    "- use iconic memory via pre-attentive attributes - our brains are hardwired to quickly pick up differences in our environment\n",
    "- consequences: direct the focus and create visual hierarchy\n",
    "- text: bold, color, size, italics, borders...\n",
    "- graphs: mainly colors, size and position\n",
    "- attention: in exploratory analysis, emphasis might be distracting, in explanatory, it's very helpful to convey information (not only data)\n",
    "- use all attributes deliberately (size, color, position)\n",
    "- color: grey vs. one color (think of colorblind, red and green - vischek, colororacle, checkmycolors)\n",
    "- test of focus: look away from visual and then bank again - where do you land?\n",
    "\n",
    "#### Think like a Designer\n",
    "- form follows function - what? how?\n",
    "\n",
    "**Affordances**: obvious how to interact with a design (knob -> turning)\n",
    "- highlight the important stuff\n",
    "- eliminate distractions\n",
    "- create clear hierarchy of information\n",
    "- sometimes \"super categories\" help (e.g. low-> high instead of clear values)\n",
    "\n",
    "**Accessibility**: being usable by people of diverse abilities\n",
    "- don't overcomplicate\n",
    "- text is your friend\n",
    "\n",
    "**Aesthetics**: prettier = easier to use/understand\n",
    "- be mindful of color, to alignment and white space\n",
    "\n",
    "**Acceptance**: by intended audience\n",
    "- change management: articulate benefits, show side by side, seen input on options, get an influential supporter\n",
    "- ask unbiased person for feedback on changed design\n",
    "\n",
    "#### Storytelling\n",
    "- magic of a story: you are able to retell it to someone else\n",
    "- parts of a story: beginning, middle and end\n",
    "\n",
    "Setup and problem statement/incident\n",
    "\n",
    "- what's in it for me? Why is it necessary?\n",
    "- what is and what could be?\n",
    "\n",
    "Attempt to resolve the problem\n",
    "\n",
    "- how to solve the problem? Options\n",
    "- examples, external content/comparisons\n",
    "- why is the audience able to do something about it?\n",
    "\n",
    "Resolution\n",
    "\n",
    "- call to action\n",
    "- conflict and tension are integral parts of stories\n",
    "- two ways to persuade:\n",
    "\n",
    "    * Intellectually by arguments (on slides?)\n",
    "    * Emotionally by arousing energy and attention\n",
    "\n",
    "- make each title the headline of a part of the story\n",
    "- narrative flow and audience: results first? Build up story? Input needed?\n",
    "- executive summary beginning and end\n",
    "- distinction between written and presented stories\n",
    "- horizontal (executive summary = slide titles) and vertical logic (each side has reinforcing content) should be checked\n",
    "- make use of repetition\n",
    "- reverse storyboarding takes the final slides and writes the main points of each down\n",
    "- fresh perspective for sparring is always helpful\n",
    "\n",
    "#### Case Studies/Examples\n",
    "- dark backgrounds: avoid if possible, as attention is redirected to the background; if necessary though, pay attention to color contrasts\n",
    "- animation: build up the graph for the audience (usually in presentations), while using annotations in the graph that is sent as a document\n",
    "- logic in order: think about the story you want to tell and arrange graph accordingly or highlight accordingly if you want to tell different stories\n",
    "- avoiding the spaghetti graph: emphasize one line at a time by highlighting; separate spatially; combined approach (all lines but one highlighted, per category)\n",
    "- alternatives to pie charts: text only, bar chart, 100% horizontal stacked bar graph, slope graph\n",
    "- advice: when stuck, think about the audience and what they should take away from the visual\n",
    "\n",
    "#### Final Thoughts:\n",
    "How to apply: \n",
    "- practice, practice, practice in the appropriate tools\n",
    "- recognize good and bad visualizations and make mental notes/reflect - imitate experts!\n",
    "- use paper for first drafts (better ideas and less attachment to the pre-work)\n",
    "- allow adequate time to storytelling with data (this is what will be presented from the data analysis you conduct - don't lose the value)\n",
    "- always iterate and seek feedback\n",
    "- have fun, play around and find your style\n",
    "- examples: eagereyes.org fiverthirtyeight.com/datalab flowingdata.com thefunctionalart.com helpmeviz.com makeapowerfulpoint.com storytellingwithdata.com wtfviz.com \n",
    "\n",
    "Building skills in the organization:\n",
    "- upskill everyone: bookclub, workshops, makeover monday, feedback loop, viz competitions\n",
    "- invest in an expert: hire or upskill a professional\n",
    "- outsource: if not possible in house"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Get predictive - machine learning <a id='step6'></a>\n",
    "- Machine learning algorithms can help you go a step further into getting insights and predicting future trends\n",
    "- Unsupervised clustering algorithms can build models to uncover trends in the data that were not distinguishable in graphs and stats\n",
    "- Supervised algorithms can predict future trends\n",
    "- Once a model is deployed, we need to operationalize it - it should not stay unused on the shelves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonasstehr/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/jonasstehr/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'parameter': [a, b, c]}\n",
    "\n",
    "# create the grid search instance\n",
    "grid = GridSearchCV(model_instance,param_grid,refit=True,verbose=3)\n",
    "# fit the model via grid search and find the best combination\n",
    "grid.fit(X_train,y_train)\n",
    "# show the best parameter combination\n",
    "grid.best_params_\n",
    "# predict the target values\n",
    "grid_predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation\n",
    "#### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Iterate and maintain <a id='step7'></a>\n",
    "- Prove the effectiveness of the project as fast as possible to justify the project\n",
    "- Maintain the model as the input and environment can change over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thanks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
